"""
êµ¬ê¸€ ìŠ¤í”„ë ˆë“œì‹œíŠ¸ì™€ ì‹¤ì‹œê°„ DB ë™ê¸°í™” ìŠ¤í¬ë¦½íŠ¸

ì£¼ìš” ê¸°ëŠ¥:
1. CSV/XLSX íŒŒì¼ì—ì„œ ì‹¤ì‹œê°„ DB ì½ê¸°
2. êµ¬ê¸€ ìŠ¤í”„ë ˆë“œì‹œíŠ¸ì—ì„œ ê¸°ì¡´ DB ì½ê¸°
3. ì˜µì…˜ID ê¸°ì¤€ìœ¼ë¡œ ì‹ ì œí’ˆ ì°¾ê¸°
4. ì‹ ì œí’ˆ ë°ì´í„°ë¥¼ ìŠ¤í”„ë ˆë“œì‹œíŠ¸ì— APPEND
"""

import gspread
import pandas as pd
from pathlib import Path
import sys
import io
import codecs

# í„°ë¯¸ë„ ì¸ì½”ë”© ì„¤ì • (Windows í•œê¸€ ê¹¨ì§ í•´ê²°)
if sys.platform == 'win32':
    try:
        # Windowsì—ì„œ UTF-8 ì¶œë ¥ ê°•ì œ
        sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
        sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')
    except:
        pass

# ===== ì„¤ì • =====
CREDENTIAL_PATH = "api-key/beaming-figure-476816-r5-7dd9d6f34342.json"
SPREADSHEET_ID = "1F0l6FMjXvKXAR9WyDvxEWcRvji-TaJbBim_G12TJ2Pw"

# ë„¤ì´ë²„/ì¿ íŒ¡ ì„¤ì •
NAVER_CONFIG = {
    "sheet_index": 0,  # 1ë²ˆ ì‹œíŠ¸
    "header_row": 1,   # 1í–‰ì´ í—¤ë”
    "option_id_column": "ìƒí’ˆë²ˆí˜¸(ìŠ¤ë§ˆíŠ¸ìŠ¤í† ì–´)",  # ë„¤ì´ë²„ëŠ” ì˜µì…˜IDê°€ ì—†ê³  ìƒí’ˆë²ˆí˜¸ë¥¼ ì‚¬ìš©
    "db_dir": "database",
    "file_pattern": "Product_*.csv"
}

COUPANG_CONFIG = {
    "sheet_index": 1,  # 2ë²ˆ ì‹œíŠ¸
    "header_row": 2,   # 2í–‰ì´ í—¤ë”
    "option_id_column": "ì˜µì…˜ ID",
    "db_dir": "database",
    "file_pattern": "price_inventory_*.xlsx"
}


# ===== í•¨ìˆ˜ ì •ì˜ =====

def get_latest_file_from_pattern(directory, file_pattern):
    """
    ë””ë ‰í† ë¦¬ì—ì„œ íŒ¨í„´ì— ë§ëŠ” ìµœì‹  íŒŒì¼ ì°¾ê¸°
    
    Args:
        directory: ë””ë ‰í† ë¦¬ ê²½ë¡œ
        file_pattern: íŒŒì¼ íŒ¨í„´ (ì˜ˆ: "Product_*.csv", "price_inventory_*.xlsx")
    
    Returns:
        Path: ìµœì‹  íŒŒì¼ ê²½ë¡œ (ì—†ìœ¼ë©´ None)
    """
    from glob import glob
    import os
    
    # glob íŒ¨í„´ ì‚¬ìš©
    pattern = os.path.join(directory, file_pattern)
    files = glob(pattern)
    
    if not files:
        return None
    
    # ìˆ˜ì • ì‹œê°„ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬í•˜ì—¬ ê°€ì¥ ìµœì‹  íŒŒì¼ ë°˜í™˜
    latest_file = max(files, key=os.path.getmtime)
    return Path(latest_file)


def get_spreadsheet_headers(worksheet, header_row_num):
    """
    ìŠ¤í”„ë ˆë“œì‹œíŠ¸ì—ì„œ í—¤ë” í–‰ ê°€ì ¸ì˜¤ê¸°
    
    Args:
        worksheet: gspread ì›Œí¬ì‹œíŠ¸ ê°ì²´
        header_row_num: í—¤ë”ê°€ ìˆëŠ” í–‰ ë²ˆí˜¸ (1-based)
    
    Returns:
        list: í—¤ë” ë¦¬ìŠ¤íŠ¸
    """
    headers = worksheet.row_values(header_row_num)
    return headers


def get_all_spreadsheet_data(worksheet, header_row_num):
    """
    ìŠ¤í”„ë ˆë“œì‹œíŠ¸ì—ì„œ ëª¨ë“  ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
    
    Args:
        worksheet: gspread ì›Œí¬ì‹œíŠ¸ ê°ì²´
        header_row_num: í—¤ë”ê°€ ìˆëŠ” í–‰ ë²ˆí˜¸ (1-based)
    
    Returns:
        list of dict: ë°ì´í„° ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸
    """
    if header_row_num == 1:
        # ì¼ë°˜ì ì¸ ê²½ìš° (1í–‰ì´ í—¤ë”)
        return worksheet.get_all_records()
    else:
        # íŠ¹ìˆ˜í•œ ê²½ìš° (ì¿ íŒ¡ì²˜ëŸ¼ 2í–‰ì´ í—¤ë”)
        # ì¤‘ë³µ í—¤ë” ì²˜ë¦¬ í•„ìš”
        all_values = worksheet.get_all_values()
        headers = all_values[header_row_num - 1]  # header_row_numì€ 1-based
        
        # ì¤‘ë³µ í—¤ë” ì²˜ë¦¬
        unique_headers = []
        used_headers = set()
        column_indices_to_keep = []
        
        for idx, header in enumerate(headers):
            header_name = header if header else f"ë¹ˆì»¬ëŸ¼_{idx}"
            
            if not header or header.strip() == "":
                if f"ë¹ˆì»¬ëŸ¼_{idx}" not in used_headers:
                    unique_headers.append(f"ë¹ˆì»¬ëŸ¼_{idx}")
                    used_headers.add(f"ë¹ˆì»¬ëŸ¼_{idx}")
                    column_indices_to_keep.append(idx)
            elif header_name not in used_headers:
                unique_headers.append(header_name)
                used_headers.add(header_name)
                column_indices_to_keep.append(idx)
        
        # ë°ì´í„° ë³€í™˜
        data_records = []
        for row_idx in range(header_row_num, len(all_values)):
            row_data = all_values[row_idx]
            record = {}
            for i, header_name in enumerate(unique_headers):
                col_idx = column_indices_to_keep[i]
                if col_idx < len(row_data):
                    record[header_name] = row_data[col_idx]
                else:
                    record[header_name] = ""
            data_records.append(record)
        
        return data_records


def read_realtime_db(file_path, header_row=0):
    """
    CSV/XLSX íŒŒì¼ì—ì„œ ì‹¤ì‹œê°„ DB ì½ê¸°
    
    Args:
        file_path: íŒŒì¼ ê²½ë¡œ
        header_row: í—¤ë”ê°€ ìˆëŠ” í–‰ ë²ˆí˜¸ (0-based, ê¸°ë³¸ê°’: 0)
    
    Returns:
        list of dict: ë°ì´í„° ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸
    """
    path = Path(file_path)
    
    if path.suffix.lower() == '.csv':
        df = pd.read_csv(file_path, header=header_row)
    elif path.suffix.lower() in ['.xlsx', '.xls']:
        df = pd.read_excel(file_path, header=header_row)
    else:
        raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹: {path.suffix}")
    
    # ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
    return df.to_dict('records')


def find_new_products(realtime_data, spreadsheet_data, option_id_column):
    """
    ì˜µì…˜ID ê¸°ì¤€ìœ¼ë¡œ ì‹ ì œí’ˆ ì°¾ê¸°
    
    Args:
        realtime_data: ì‹¤ì‹œê°„ DB ë°ì´í„° (ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸)
        spreadsheet_data: ìŠ¤í”„ë ˆë“œì‹œíŠ¸ ë°ì´í„° (ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸)
        option_id_column: ì˜µì…˜ID ì»¬ëŸ¼ëª…
    
    Returns:
        list of dict: ì‹ ì œí’ˆ ë¦¬ìŠ¤íŠ¸
    """
    # ê¸°ì¡´ ì˜µì…˜ID ì§‘í•© ìƒì„±
    existing_option_ids = set()
    for row in spreadsheet_data:
        option_id = row.get(option_id_column, '')
        if option_id:
            existing_option_ids.add(str(option_id))
    
    # ì‹ ì œí’ˆ í•„í„°ë§
    new_products = []
    for row in realtime_data:
        option_id = str(row.get(option_id_column, ''))
        if option_id and option_id not in existing_option_ids:
            new_products.append(row)
    
    return new_products


def align_to_spreadsheet_headers(realtime_dict, spreadsheet_headers):
    """
    ì‹¤ì‹œê°„ DB ë°ì´í„°ë¥¼ ìŠ¤í”„ë ˆë“œì‹œíŠ¸ í—¤ë” ìˆœì„œë¡œ ì •ë ¬
    
    Args:
        realtime_dict: ì‹¤ì‹œê°„ DB ë”•ì…”ë„ˆë¦¬
        spreadsheet_headers: ìŠ¤í”„ë ˆë“œì‹œíŠ¸ í—¤ë” ë¦¬ìŠ¤íŠ¸
    
    Returns:
        list: ì •ë ¬ëœ ë°ì´í„° ë¦¬ìŠ¤íŠ¸
    """
    import math
    
    aligned_row = []
    for header in spreadsheet_headers:
        # ìƒí’ˆì½”ë“œ ì»¬ëŸ¼ì€ ì‚¬ìš©ìê°€ ì§ì ‘ ì°½ê³  ìœ„ì¹˜ë¥¼ ì…ë ¥í•˜ëŠ” ê³³ì´ë¯€ë¡œ
        # ì‹ ê·œ ì œí’ˆ ì¶”ê°€ ì‹œ ë°˜ë“œì‹œ ë¹ˆì¹¸ìœ¼ë¡œ ì„¤ì •
        if header == "ìƒí’ˆì½”ë“œ":
            value = ""
        else:
            value = realtime_dict.get(header, "")
        
        # NaN ì²˜ë¦¬: Google Sheetsì—ì„œ NaNì„ JSONìœ¼ë¡œ ë³€í™˜í•  ìˆ˜ ì—†ìŒ
        if isinstance(value, float) and math.isnan(value):
            value = ""
        
        aligned_row.append(value)
    
    return aligned_row


def append_to_spreadsheet(worksheet, new_data_list, header_row_num):
    """
    ìŠ¤í”„ë ˆë“œì‹œíŠ¸ì— ë°ì´í„° ì¶”ê°€ (ì„œì‹ í¬í•¨)
    
    Args:
        worksheet: gspread ì›Œí¬ì‹œíŠ¸ ê°ì²´
        new_data_list: ì¶”ê°€í•  ë°ì´í„° ë¦¬ìŠ¤íŠ¸ (ê° í•­ëª©ì€ ë¦¬ìŠ¤íŠ¸ í˜•íƒœ)
        header_row_num: í—¤ë” í–‰ ë²ˆí˜¸ (1-based)
    """
    if not new_data_list:
        return
    
    # ë°ì´í„° ì¶”ê°€ ì „ ë§ˆì§€ë§‰ ë°ì´í„° í–‰ ë²ˆí˜¸ ì €ì¥
    all_values = worksheet.get_all_values()
    last_data_row = len(all_values)  # ë§ˆì§€ë§‰ í–‰ ë²ˆí˜¸ (1-based)
    
    # ë°ì´í„° ì¶”ê°€
    worksheet.append_rows(new_data_list)
    
    # ì¶”ê°€ëœ í–‰ì˜ ì‹œì‘ê³¼ ë í–‰ ë²ˆí˜¸ ê³„ì‚°
    added_rows_start = last_data_row + 1
    added_rows_end = last_data_row + len(new_data_list)
    
    print(f"âœ… {len(new_data_list)}ê°œì˜ ìƒˆ ì œí’ˆì´ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤ (í–‰ {added_rows_start}-{added_rows_end})")
    
    # ì„œì‹ ë³µì‚¬: ë§ˆì§€ë§‰ ë°ì´í„° í–‰ì˜ ì„œì‹ì„ ìƒˆë¡œ ì¶”ê°€ëœ í–‰ì— ë³µì‚¬
    try:
        # ë§ˆì§€ë§‰ ë°ì´í„° í–‰ ì°¾ê¸° (í—¤ë” ì œì™¸)
        source_row = header_row_num + 1  # í—¤ë” ë‹¤ìŒ í–‰ë¶€í„° ì‹œì‘
        
        if last_data_row > header_row_num:
            # ì‹¤ì œ ë°ì´í„°ê°€ ìˆëŠ” ê²½ìš°, ë§ˆì§€ë§‰ ë°ì´í„° í–‰ì˜ ì„œì‹ ì‚¬ìš©
            source_row = last_data_row
        
        # Google Sheets APIë¥¼ ì‚¬ìš©í•˜ì—¬ ì„œì‹ ë³µì‚¬
        spreadsheet = worksheet.spreadsheet
        sheet_id = worksheet.id
        
        # ì„œì‹ ë³µì‚¬ ìš”ì²­ (copyPaste ì‚¬ìš©)
        requests = [{
            'copyPaste': {
                'source': {
                    'sheetId': sheet_id,
                    'startRowIndex': source_row - 1,  # 0-based
                    'endRowIndex': source_row,  # 0-based (ë‹¤ìŒ í–‰ ì „ê¹Œì§€)
                    'startColumnIndex': 0,
                    'endColumnIndex': len(new_data_list[0]) if new_data_list else 1
                },
                'destination': {
                    'sheetId': sheet_id,
                    'startRowIndex': added_rows_start - 1,  # 0-based
                    'endRowIndex': added_rows_end,  # 0-based
                    'startColumnIndex': 0,
                    'endColumnIndex': len(new_data_list[0]) if new_data_list else 1
                },
                'pasteType': 'PASTE_FORMAT',
                'pasteOrientation': 'NORMAL'
            }
        }]
        
        spreadsheet.batch_update({'requests': requests})
        print(f"âœ… ì„œì‹ ë³µì‚¬ ì™„ë£Œ (í–‰ {source_row} â†’ í–‰ {added_rows_start}-{added_rows_end})")
        
    except Exception as e:
        print(f"âš ï¸  ì„œì‹ ë³µì‚¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ (ë°ì´í„°ëŠ” ì •ìƒ ì¶”ê°€ë¨): {str(e)}")


def sync_naver(realtime_file_path=None, test_mode=True, test_count=None):
    """
    ë„¤ì´ë²„ ì‹¤ì‹œê°„ DBì™€ ìŠ¤í”„ë ˆë“œì‹œíŠ¸ ë™ê¸°í™”
    
    Args:
        realtime_file_path: ì‹¤ì‹œê°„ DB íŒŒì¼ ê²½ë¡œ (Noneì´ë©´ ìµœì‹  íŒŒì¼ ìë™ ì„ íƒ)
        test_mode: í…ŒìŠ¤íŠ¸ ëª¨ë“œ ì—¬ë¶€ (Trueë©´ ì¶”ê°€í•˜ì§€ ì•ŠìŒ, Falseë©´ ì¶”ê°€í•¨)
        test_count: í…ŒìŠ¤íŠ¸ ì¶”ê°€ ê°œìˆ˜ (Noneì´ë©´ ëª¨ë“  ì œí’ˆ, ìˆ«ìë©´ ì§€ì • ê°œìˆ˜ë§Œ)
    """
    print("\n" + "="*80)
    print("ğŸ”µ ë„¤ì´ë²„ ë™ê¸°í™” ì‹œì‘")
    print("="*80)
    
    # 1ë‹¨ê³„: ì‹¤ì‹œê°„ DB ì½ê¸°
    if realtime_file_path is None:
        # ìµœì‹  íŒŒì¼ ìë™ ì„ íƒ
        latest_file = get_latest_file_from_pattern(
            NAVER_CONFIG["db_dir"],
            NAVER_CONFIG["file_pattern"]
        )
        if latest_file is None:
            print(f"âŒ ì˜¤ë¥˜: {NAVER_CONFIG['db_dir']}ì—ì„œ {NAVER_CONFIG['file_pattern']} íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return
        realtime_file_path = latest_file
    
    print(f"ğŸ“‚ ì‹¤ì‹œê°„ DB ì½ê¸°: {realtime_file_path}")
    # ë„¤ì´ë²„ëŠ” CSV íŒŒì¼ì´ë¯€ë¡œ ì²« ë²ˆì§¸ í–‰(0)ì´ í—¤ë”
    realtime_data = read_realtime_db(str(realtime_file_path), header_row=0)
    print(f"âœ… ì‹¤ì‹œê°„ DB: {len(realtime_data)}ê°œ ì œí’ˆ")
    
    # 2ë‹¨ê³„: ìŠ¤í”„ë ˆë“œì‹œíŠ¸ ë°ì´í„° ì½ê¸°
    print("\nğŸ“Š ìŠ¤í”„ë ˆë“œì‹œíŠ¸ì—ì„œ ê¸°ì¡´ ë°ì´í„° ì½ê¸°...")
    gc = gspread.service_account(filename=CREDENTIAL_PATH)
    spreadsheet = gc.open_by_key(SPREADSHEET_ID)
    worksheet = spreadsheet.get_worksheet(NAVER_CONFIG["sheet_index"])
    
    spreadsheet_data = get_all_spreadsheet_data(worksheet, NAVER_CONFIG["header_row"])
    print(f"âœ… ê¸°ì¡´ DB: {len(spreadsheet_data)}ê°œ ì œí’ˆ")
    
    # 3ë‹¨ê³„: í—¤ë” ê°€ì ¸ì˜¤ê¸°
    spreadsheet_headers = get_spreadsheet_headers(worksheet, NAVER_CONFIG["header_row"])
    
    # 4ë‹¨ê³„: ì‹ ì œí’ˆ ì°¾ê¸°
    print(f"\nğŸ” ì‹ ì œí’ˆ ê²€ìƒ‰ ì¤‘... (ì˜µì…˜ID: {NAVER_CONFIG['option_id_column']})")
    
    # ê¸°ì¡´ ì œí’ˆ ìƒì„¸ ë¡œê¹…
    print("\nğŸ“‹ ê¸°ì¡´ ì œí’ˆ ìƒ˜í”Œ (ì²˜ìŒ 10ê°œ):")
    for i, row in enumerate(spreadsheet_data[:10]):
        option_id = row.get(NAVER_CONFIG['option_id_column'], 'N/A')
        product_name = row.get('ìƒí’ˆëª…', 'N/A')
        price = row.get('íŒë§¤ê°€', 'N/A')
        stock = row.get('ì¬ê³ ìˆ˜ëŸ‰', 'N/A')
        print(f"  [{i+1}] ìƒí’ˆë²ˆí˜¸: {option_id}, ìƒí’ˆëª…: {product_name}, ê°€ê²©: {price}, ì¬ê³ : {stock}")
    
    # ì‹¤ì‹œê°„ ì œí’ˆ ìƒ˜í”Œ ë¡œê¹…
    print("\nğŸ“‹ ì‹¤ì‹œê°„ DB ìƒ˜í”Œ (ì²˜ìŒ 10ê°œ):")
    for i, row in enumerate(realtime_data[:10]):
        option_id = row.get(NAVER_CONFIG['option_id_column'], 'N/A')
        product_name = row.get('ìƒí’ˆëª…', 'N/A')
        price = row.get('íŒë§¤ê°€', 'N/A')
        stock = row.get('ì¬ê³ ìˆ˜ëŸ‰', 'N/A')
        print(f"  [{i+1}] ìƒí’ˆë²ˆí˜¸: {option_id}, ìƒí’ˆëª…: {product_name}, ê°€ê²©: {price}, ì¬ê³ : {stock}")
    
    # ì‹ ì œí’ˆ ì°¾ê¸°
    new_products = find_new_products(
        realtime_data, 
        spreadsheet_data, 
        NAVER_CONFIG["option_id_column"]
    )
    print(f"\nâœ… ì‹ ì œí’ˆ ë°œê²¬: {len(new_products)}ê°œ")
    
    # ì‹ ì œí’ˆ ìƒì„¸ ë¡œê¹…
    if new_products:
        print("\nğŸ†• ì‹ ì œí’ˆ ëª©ë¡ (ì „ë¶€ í‘œì‹œ):")
        for i, product in enumerate(new_products):
            option_id = product.get(NAVER_CONFIG['option_id_column'], 'N/A')
            product_name = product.get('ìƒí’ˆëª…', 'N/A')
            price = product.get('íŒë§¤ê°€', 'N/A')
            stock = product.get('ì¬ê³ ìˆ˜ëŸ‰', 'N/A')
            print(f"  [{i+1}] ìƒí’ˆë²ˆí˜¸: {option_id}, ìƒí’ˆëª…: {product_name}, ê°€ê²©: {price}, ì¬ê³ : {stock}")
    
    # 5ë‹¨ê³„: ë°ì´í„° ë³€í™˜ ë° ì¶”ê°€
    if new_products:
        # í…ŒìŠ¤íŠ¸ ê°œìˆ˜ ì œí•œ (í•œ ê°œì”©ë§Œ ì¶”ê°€ í…ŒìŠ¤íŠ¸ìš©)
        products_to_add = new_products
        if test_count is not None and test_count > 0:
            products_to_add = new_products[:test_count]
            print(f"\nğŸ§ª í…ŒìŠ¤íŠ¸ ëª¨ë“œ: {test_count}ê°œ ì œí’ˆë§Œ ì¶”ê°€í•©ë‹ˆë‹¤.")
        
        if test_mode:
            print(f"\nğŸ“ ì¶”ê°€ ì˜ˆì • ì œí’ˆ ìˆ˜: {len(products_to_add)}ê°œ")
            print("âš ï¸  í…ŒìŠ¤íŠ¸ ëª¨ë“œ: ì‹¤ì œë¡œ ìŠ¤í”„ë ˆë“œì‹œíŠ¸ì— ì¶”ê°€í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        else:
            print(f"\nğŸ“ ì¶”ê°€í•  ì œí’ˆ ìˆ˜: {len(products_to_add)}ê°œ")
            new_rows = []
            for product in products_to_add:
                aligned_row = align_to_spreadsheet_headers(product, spreadsheet_headers)
                new_rows.append(aligned_row)
            append_to_spreadsheet(worksheet, new_rows, NAVER_CONFIG["header_row"])
    else:
        print("\nâœ… ìƒˆ ì œí’ˆì´ ì—†ìŠµë‹ˆë‹¤. ë™ê¸°í™” ì™„ë£Œ!")
    
    print("\n" + "="*80)


def sync_coupang(realtime_file_path=None, test_mode=True, test_count=None):
    """
    ì¿ íŒ¡ ì‹¤ì‹œê°„ DBì™€ ìŠ¤í”„ë ˆë“œì‹œíŠ¸ ë™ê¸°í™”
    
    Args:
        realtime_file_path: ì‹¤ì‹œê°„ DB íŒŒì¼ ê²½ë¡œ (Noneì´ë©´ ìµœì‹  íŒŒì¼ ìë™ ì„ íƒ)
        test_mode: í…ŒìŠ¤íŠ¸ ëª¨ë“œ ì—¬ë¶€ (Trueë©´ ì¶”ê°€í•˜ì§€ ì•ŠìŒ, Falseë©´ ì¶”ê°€í•¨)
        test_count: í…ŒìŠ¤íŠ¸ ì¶”ê°€ ê°œìˆ˜ (Noneì´ë©´ ëª¨ë“  ì œí’ˆ, ìˆ«ìë©´ ì§€ì • ê°œìˆ˜ë§Œ)
    """
    print("\n" + "="*80)
    print("ğŸŸ¡ ì¿ íŒ¡ ë™ê¸°í™” ì‹œì‘")
    print("="*80)
    
    # 1ë‹¨ê³„: ì‹¤ì‹œê°„ DB ì½ê¸°
    if realtime_file_path is None:
        # ìµœì‹  íŒŒì¼ ìë™ ì„ íƒ
        latest_file = get_latest_file_from_pattern(
            COUPANG_CONFIG["db_dir"],
            COUPANG_CONFIG["file_pattern"]
        )
        if latest_file is None:
            print(f"âŒ ì˜¤ë¥˜: {COUPANG_CONFIG['db_dir']}ì—ì„œ {COUPANG_CONFIG['file_pattern']} íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return
        realtime_file_path = latest_file
    
    print(f"ğŸ“‚ ì‹¤ì‹œê°„ DB ì½ê¸°: {realtime_file_path}")
    # ì¿ íŒ¡ì€ XLSX íŒŒì¼ì´ê³  3í–‰(ì¸ë±ìŠ¤ 2)ì´ í—¤ë”
    realtime_data = read_realtime_db(str(realtime_file_path), header_row=2)
    print(f"âœ… ì‹¤ì‹œê°„ DB: {len(realtime_data)}ê°œ ì œí’ˆ")
    
    # 2ë‹¨ê³„: ìŠ¤í”„ë ˆë“œì‹œíŠ¸ ë°ì´í„° ì½ê¸°
    print("\nğŸ“Š ìŠ¤í”„ë ˆë“œì‹œíŠ¸ì—ì„œ ê¸°ì¡´ ë°ì´í„° ì½ê¸°...")
    gc = gspread.service_account(filename=CREDENTIAL_PATH)
    spreadsheet = gc.open_by_key(SPREADSHEET_ID)
    worksheet = spreadsheet.get_worksheet(COUPANG_CONFIG["sheet_index"])
    
    spreadsheet_data = get_all_spreadsheet_data(worksheet, COUPANG_CONFIG["header_row"])
    print(f"âœ… ê¸°ì¡´ DB: {len(spreadsheet_data)}ê°œ ì œí’ˆ")
    
    # 3ë‹¨ê³„: í—¤ë” ê°€ì ¸ì˜¤ê¸°
    spreadsheet_headers = get_spreadsheet_headers(worksheet, COUPANG_CONFIG["header_row"])
    
    # 4ë‹¨ê³„: ì‹ ì œí’ˆ ì°¾ê¸°
    print(f"\nğŸ” ì‹ ì œí’ˆ ê²€ìƒ‰ ì¤‘... (ì˜µì…˜ID: {COUPANG_CONFIG['option_id_column']})")
    
    # ê¸°ì¡´ ì œí’ˆ ìƒì„¸ ë¡œê¹…
    print("\nğŸ“‹ ê¸°ì¡´ ì œí’ˆ ìƒ˜í”Œ (ì²˜ìŒ 10ê°œ):")
    for i, row in enumerate(spreadsheet_data[:10]):
        option_id = row.get(COUPANG_CONFIG['option_id_column'], 'N/A')
        product_name = row.get('ì¿ íŒ¡ ë…¸ì¶œ ìƒí’ˆëª…', 'N/A')
        price = row.get('íŒë§¤ê°€ê²©', 'N/A')
        stock = row.get('ì”ì—¬ìˆ˜ëŸ‰(ì¬ê³ )', 'N/A')
        print(f"  [{i+1}] ì˜µì…˜ID: {option_id}, ìƒí’ˆëª…: {product_name}, ê°€ê²©: {price}, ì¬ê³ : {stock}")
    
    # ì‹¤ì‹œê°„ ì œí’ˆ ìƒ˜í”Œ ë¡œê¹…
    print("\nğŸ“‹ ì‹¤ì‹œê°„ DB ìƒ˜í”Œ (ì²˜ìŒ 10ê°œ):")
    for i, row in enumerate(realtime_data[:10]):
        option_id = row.get(COUPANG_CONFIG['option_id_column'], 'N/A')
        product_name = row.get('ì¿ íŒ¡ ë…¸ì¶œ ìƒí’ˆëª…', 'N/A')
        price = row.get('íŒë§¤ê°€ê²©', 'N/A')
        stock = row.get('ì”ì—¬ìˆ˜ëŸ‰(ì¬ê³ )', 'N/A')
        print(f"  [{i+1}] ì˜µì…˜ID: {option_id}, ìƒí’ˆëª…: {product_name}, ê°€ê²©: {price}, ì¬ê³ : {stock}")
    
    # ì‹ ì œí’ˆ ì°¾ê¸°
    new_products = find_new_products(
        realtime_data, 
        spreadsheet_data, 
        COUPANG_CONFIG["option_id_column"]
    )
    print(f"\nâœ… ì‹ ì œí’ˆ ë°œê²¬: {len(new_products)}ê°œ")
    
    # ì‹ ì œí’ˆ ìƒì„¸ ë¡œê¹…
    if new_products:
        print("\nğŸ†• ì‹ ì œí’ˆ ëª©ë¡ (ì „ë¶€ í‘œì‹œ):")
        for i, product in enumerate(new_products):
            option_id = product.get(COUPANG_CONFIG['option_id_column'], 'N/A')
            product_name = product.get('ì¿ íŒ¡ ë…¸ì¶œ ìƒí’ˆëª…', 'N/A')
            price = product.get('íŒë§¤ê°€ê²©', 'N/A')
            stock = product.get('ì”ì—¬ìˆ˜ëŸ‰(ì¬ê³ )', 'N/A')
            print(f"  [{i+1}] ì˜µì…˜ID: {option_id}, ìƒí’ˆëª…: {product_name}, ê°€ê²©: {price}, ì¬ê³ : {stock}")
    
    # 5ë‹¨ê³„: ë°ì´í„° ë³€í™˜ ë° ì¶”ê°€
    if new_products:
        # í…ŒìŠ¤íŠ¸ ê°œìˆ˜ ì œí•œ (í•œ ê°œì”©ë§Œ ì¶”ê°€ í…ŒìŠ¤íŠ¸ìš©)
        products_to_add = new_products
        if test_count is not None and test_count > 0:
            products_to_add = new_products[:test_count]
            print(f"\nğŸ§ª í…ŒìŠ¤íŠ¸ ëª¨ë“œ: {test_count}ê°œ ì œí’ˆë§Œ ì¶”ê°€í•©ë‹ˆë‹¤.")
        
        if test_mode:
            print(f"\nğŸ“ ì¶”ê°€ ì˜ˆì • ì œí’ˆ ìˆ˜: {len(products_to_add)}ê°œ")
            print("âš ï¸  í…ŒìŠ¤íŠ¸ ëª¨ë“œ: ì‹¤ì œë¡œ ìŠ¤í”„ë ˆë“œì‹œíŠ¸ì— ì¶”ê°€í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        else:
            print(f"\nğŸ“ ì¶”ê°€í•  ì œí’ˆ ìˆ˜: {len(products_to_add)}ê°œ")
            new_rows = []
            for product in products_to_add:
                aligned_row = align_to_spreadsheet_headers(product, spreadsheet_headers)
                new_rows.append(aligned_row)
            append_to_spreadsheet(worksheet, new_rows, COUPANG_CONFIG["header_row"])
    else:
        print("\nâœ… ìƒˆ ì œí’ˆì´ ì—†ìŠµë‹ˆë‹¤. ë™ê¸°í™” ì™„ë£Œ!")
    
    print("\n" + "="*80)


# ===== ë©”ì¸ ì‹¤í–‰ =====

if __name__ == "__main__":
    print("="*80)
    print("ğŸ›’ ìƒí’ˆ DB ë™ê¸°í™” ìŠ¤í¬ë¦½íŠ¸")
    print("="*80)
    print("\nì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” database í´ë”ì—ì„œ ìµœì‹  íŒŒì¼ì„ ìë™ìœ¼ë¡œ ì°¾ì•„ ë™ê¸°í™”í•©ë‹ˆë‹¤.")
    print("="*80)
    
    # í…ŒìŠ¤íŠ¸ ëª¨ë“œ ì„¤ì •
    # ë¡œê¹…ë§Œ í•˜ë ¤ë©´: test_mode=True, test_count=None
    # í•œ ê°œì”©ë§Œ ì¶”ê°€ í…ŒìŠ¤íŠ¸í•˜ë ¤ë©´: test_mode=False, test_count=1
    # ì „ì²´ ì¶”ê°€í•˜ë ¤ë©´: test_mode=False, test_count=None
    
    print("\n" + "="*80)
    print("ğŸ§ª í…ŒìŠ¤íŠ¸ ëª¨ë“œ: ë„¤ì´ë²„ 1ê°œ, ì¿ íŒ¡ 1ê°œ ì œí’ˆ ì¶”ê°€ í…ŒìŠ¤íŠ¸")
    print("="*80)
    
    # ë„¤ì´ë²„: 1ê°œ ì œí’ˆë§Œ ì‹¤ì œ ì¶”ê°€
    # sync_naver(test_mode=False, test_count=1)
    sync_naver(test_mode=False, test_count=None)
    
    # ì¿ íŒ¡: 1ê°œ ì œí’ˆë§Œ ì‹¤ì œ ì¶”ê°€
    # sync_coupang(test_mode=False, test_count=1)
    sync_coupang(test_mode=False, test_count=None)
    
    print("\n" + "="*80)
    print("âœ… í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
    print("\nğŸ’¡ ëª¨ë“  ì œí’ˆ ì¶”ê°€í•˜ë ¤ë©´ test_mode=False, test_count=Noneìœ¼ë¡œ ë³€ê²½í•˜ì„¸ìš”")

